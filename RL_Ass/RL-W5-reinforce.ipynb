{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RL-W5-reinforce.ipynb","provenance":[{"file_id":"https://github.com/yandexdataschool/Practical_RL/blob/coursera/week5_policy_based/practice_reinforce.ipynb","timestamp":1588622340779}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"of6CzqL9J_DV","colab_type":"text"},"source":["# REINFORCE in TensorFlow\n","\n","Just like we did before for q-learning, this time we'll design a neural network to learn `CartPole-v0` via policy gradient (REINFORCE)."]},{"cell_type":"code","metadata":{"id":"6k4FvkfKJ_DW","colab_type":"code","colab":{}},"source":["import sys, os\n","if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n","    %tensorflow_version 1.x\n","    \n","    if not os.path.exists('.setup_complete'):\n","        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring20/setup_colab.sh -O- | bash\n","\n","        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n","        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week5_policy_based/submit.py\n","\n","        !touch .setup_complete\n","\n","# This code creates a virtual display to draw game images on.\n","# It will have no effect if your machine has a monitor.\n","if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n","    !bash ../xvfb start\n","    os.environ['DISPLAY'] = ':1'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"txHTlG90J_Dc","colab_type":"text"},"source":["A caveat: we have received reports that the following cell may crash with `NameError: name 'base' is not defined`. The [suggested workaround](https://www.coursera.org/learn/practical-rl/discussions/all/threads/N2Pw652iEemRYQ6W2GuqHg/replies/te3HpQwOQ62tx6UMDoOt2Q/comments/o08gTqelT9KPIE6npX_S3A) is to install `gym==0.14.0` and `pyglet==1.3.2`."]},{"cell_type":"code","metadata":{"id":"XIbeIkaNJ_Dd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":286},"outputId":"d7eacf96-2750-4cab-b34b-93b4a0c27817","executionInfo":{"status":"ok","timestamp":1588624874429,"user_tz":240,"elapsed":2052,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gir3kM1ZUDhmarZZYcyrRZZ5vrnZpxHHj7QcmQy2g=s64","userId":"07041430737003441740"}}},"source":["import gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","env = gym.make(\"CartPole-v0\")\n","\n","# gym compatibility: unwrap TimeLimit\n","if hasattr(env, '_max_episode_steps'):\n","    env = env.env\n","\n","env.reset()\n","n_actions = env.action_space.n\n","state_dim = env.observation_space.shape\n","\n","plt.imshow(env.render(\"rgb_array\"))"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fa5c2652518>"]},"metadata":{"tags":[]},"execution_count":3},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"SnJV7btXJ_Di","colab_type":"text"},"source":["# Building the network for REINFORCE"]},{"cell_type":"markdown","metadata":{"id":"JLTZDrpLJ_Dj","colab_type":"text"},"source":["For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n","\n","For numerical stability, please __do not include the softmax layer into your network architecture__.\n","We'll use softmax or log-softmax where appropriate."]},{"cell_type":"code","metadata":{"id":"mq_31OIVJ_Dj","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","# create input variables. We only need <s,a,R> for REINFORCE\n","states = tf.placeholder('float32', (None,)+state_dim, name=\"states\")\n","actions = tf.placeholder('int32', name=\"action_ids\")\n","cumulative_rewards = tf.placeholder('float32', name=\"cumulative_returns\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPhDDFyZJ_Dm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"58e88ae1-57ff-434c-8bf9-39d74c07c6e0","executionInfo":{"status":"ok","timestamp":1588625182844,"user_tz":240,"elapsed":375,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gir3kM1ZUDhmarZZYcyrRZZ5vrnZpxHHj7QcmQy2g=s64","userId":"07041430737003441740"}}},"source":["# <define network graph using raw tf or any deep learning library>\n","import keras\n","from keras.layers import Dense\n","\n","model = keras.models.Sequential()\n","model.add(Dense(128, activation='relu', input_shape=state_dim))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(n_actions, activation='linear'))\n","\n","logits = model(states) # <linear outputs(symbolic) of your network>\n","\n","policy = tf.nn.softmax(logits)\n","log_policy = tf.nn.log_softmax(logits)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Mo1WqHD7J_Dp","colab_type":"code","colab":{}},"source":["# utility function to pick action in one given state\n","def get_action_proba(s):\n","    return policy.eval({states: [s]})[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jWMVkjbKJ_Dt","colab_type":"text"},"source":["#### Loss function and updates\n","\n","We now need to define objective and update over policy gradient.\n","\n","Our objective function is\n","\n","$$ J \\approx  { 1 \\over N } \\sum_{s_i,a_i} G(s_i,a_i) $$\n","\n","\n","Following the REINFORCE algorithm, we can define our objective as follows: \n","\n","$$ \\hat J \\approx { 1 \\over N } \\sum_{s_i,a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G(s_i,a_i) $$\n","\n","When you compute gradient of that function over network weights $ \\theta $, it will become exactly the policy gradient."]},{"cell_type":"code","metadata":{"id":"3wQ_gkrhJ_Dt","colab_type":"code","colab":{}},"source":["# select log-probabilities for chosen actions, log pi(a_i|s_i)\n","indices = tf.stack([tf.range(tf.shape(log_policy)[0]), actions], axis=-1)\n","log_policy_for_actions = tf.gather_nd(log_policy, indices)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vWjh3tQOJ_Dy","colab_type":"code","colab":{}},"source":["# policy objective as in the last formula. please use mean, not sum.\n","# note: you need to use log_policy_for_actions to get log probabilities for actions taken.\n","\n","J = tf.reduce_mean(log_policy_for_actions*cumulative_rewards) # <YOUR CODE>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7B7ZpoPlJ_D2","colab_type":"code","colab":{}},"source":["# regularize with entropy\n","entropy = -tf.reduce_sum(policy*log_policy, axis=1) # <compute entropy. Don't forget the sign!>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"18d6sPQUJ_D5","colab_type":"code","colab":{}},"source":["# all network weights\n","all_weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) # <a list of all trainable weights in your network>\n","\n","# weight updates. maximizing J is same as minimizing -J. Adding negative entropy.\n","loss = -J - 0.1*entropy\n","\n","update = tf.train.AdamOptimizer().minimize(loss, var_list=all_weights)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2eBaZ1srJ_D8","colab_type":"text"},"source":["### Computing cumulative rewards"]},{"cell_type":"code","metadata":{"id":"oYSQcmAuJ_D9","colab_type":"code","colab":{}},"source":["\n","\n","def get_cumulative_rewards(rewards,  # rewards at each step\n","                           gamma=0.99  # discount for reward\n","                           ):\n","    \"\"\"\n","    take a list of immediate rewards r(s,a) for the whole session \n","    compute cumulative rewards R(s,a) (a.k.a. G(s,a) in Sutton '16)\n","    R_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n","\n","    The simple way to compute cumulative rewards is to iterate from last to first time tick\n","    and compute R_t = r_t + gamma*R_{t+1} recurrently\n","\n","    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n","    \"\"\"\n","    # <YOUR CODE>\n","    cumulative_rewards = np.array(rewards).astype(np.float32)\n","    for i in range(len(rewards)-2, -1, -1):\n","        cumulative_rewards[i] += gamma*cumulative_rewards[i+1]\n","        \n","    return cumulative_rewards # <YOUR CODE: array of cumulative rewards>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_vcLxfUJ_ED","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3fd496d8-88d8-43df-f987-ae93e6b72291","executionInfo":{"status":"ok","timestamp":1588625349821,"user_tz":240,"elapsed":330,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gir3kM1ZUDhmarZZYcyrRZZ5vrnZpxHHj7QcmQy2g=s64","userId":"07041430737003441740"}}},"source":["assert len(get_cumulative_rewards(range(100))) == 100\n","assert np.allclose(\n","    get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n","    [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n","assert np.allclose(\n","    get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n","    [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n","assert np.allclose(\n","    get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n","    [0, 0, 1, 2, 3, 4, 0])\n","print(\"looks good!\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["looks good!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jxqG7e1nJ_EH","colab_type":"code","colab":{}},"source":["def train_step(_states, _actions, _rewards):\n","    \"\"\"given full session, trains agent with policy gradient\"\"\"\n","    _cumulative_rewards = get_cumulative_rewards(_rewards)\n","    update.run({states: _states, actions: _actions,\n","                cumulative_rewards: _cumulative_rewards})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PGA1xQyvJ_EK","colab_type":"text"},"source":["### Playing the game"]},{"cell_type":"code","metadata":{"id":"MEN3xq4xJ_EK","colab_type":"code","colab":{}},"source":["def generate_session(env, t_max=1000):\n","    \"\"\"play env with REINFORCE agent and train at the session end\"\"\"\n","\n","    # arrays to record session\n","    states, actions, rewards = [], [], []\n","\n","    s = env.reset()\n","\n","    for t in range(t_max):\n","\n","        # action probabilities array aka pi(a|s)\n","        action_probas = get_action_proba(s)\n","\n","        a = np.random.choice(n_actions, p=action_probas) # <pick random action using action_probas>\n","\n","        new_s, r, done, info = env.step(a)\n","\n","        # record session history to train later\n","        states.append(s)\n","        actions.append(a)\n","        rewards.append(r)\n","\n","        s = new_s\n","        if done:\n","            break\n","\n","    train_step(states, actions, rewards)\n","\n","    # technical: return session rewards to print them later\n","    return sum(rewards)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aj4fMEHZJ_EM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"outputId":"51eecf84-8837-4202-ed55-a3a82603b91a","executionInfo":{"status":"ok","timestamp":1588625445222,"user_tz":240,"elapsed":56474,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gir3kM1ZUDhmarZZYcyrRZZ5vrnZpxHHj7QcmQy2g=s64","userId":"07041430737003441740"}}},"source":["s = tf.InteractiveSession()\n","s.run(tf.global_variables_initializer())\n","\n","for i in range(100):\n","\n","    rewards = [generate_session(env) for _ in range(100)]  # generate new sessions\n","\n","    print(\"mean reward:%.3f\" % (np.mean(rewards)))\n","\n","    if np.mean(rewards) > 300:\n","        print(\"You Win!\")  # but you can train even further\n","        break"],"execution_count":17,"outputs":[{"output_type":"stream","text":["mean reward:44.740\n","mean reward:141.450\n","mean reward:263.610\n","mean reward:597.590\n","You Win!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z-nGsS76J_EP","colab_type":"text"},"source":["### Results & video"]},{"cell_type":"code","metadata":{"id":"rYqWpjXZJ_EP","colab_type":"code","colab":{}},"source":["# record sessions\n","import gym.wrappers\n","monitor_env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True)\n","sessions = [generate_session(monitor_env) for _ in range(100)]\n","monitor_env.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5GfoIAQJ_ET","colab_type":"code","colab":{"resources":{"http://localhost:8080/videos/openaigym.video.0.123.video000008.mp4":{"data":"CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K","ok":false,"headers":[["content-length","1449"],["content-type","text/html; charset=utf-8"]],"status":404,"status_text":""}},"base_uri":"https://localhost:8080/","height":501},"outputId":"e28eef1f-94ce-47f7-a06b-1f9d1759b974","executionInfo":{"status":"ok","timestamp":1588626893969,"user_tz":240,"elapsed":312,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gir3kM1ZUDhmarZZYcyrRZZ5vrnZpxHHj7QcmQy2g=s64","userId":"07041430737003441740"}}},"source":["# show video\n","from IPython.display import HTML\n","import os\n","\n","video_names = list(\n","    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n","\n","HTML(\"\"\"\n","<video width=\"640\" height=\"480\" controls>\n","  <source src=\"{}\" type=\"video/mp4\">\n","</video>\n","\"\"\".format(\"./videos/\" + video_names[-2]))  # this may or may not be _last_ video. Try other indices"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","<video width=\"640\" height=\"480\" controls>\n","  <source src=\"./videos/openaigym.video.0.123.video000008.mp4\" type=\"video/mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"c5bOBcyFJ_EY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"735da1fd-c68f-4f5b-f048-13d98b29f3dd","executionInfo":{"status":"ok","timestamp":1588625541939,"user_tz":240,"elapsed":30982,"user":{"displayName":"Hieu Quoc Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gir3kM1ZUDhmarZZYcyrRZZ5vrnZpxHHj7QcmQy2g=s64","userId":"07041430737003441740"}}},"source":["from submit import submit_cartpole\n","submit_cartpole(generate_session, \"ng.hieu100@gmail.com\", \"dHUs3R3H8yPAtYhB\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Submitted to Coursera platform. See results on assignment page!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VFB9owwBJ_Ea","colab_type":"code","colab":{}},"source":["# That's all, thank you for your attention!\n","# Not having enough? There's an actor-critic waiting for you in the honor section.\n","# But make sure you've seen the videos first."],"execution_count":0,"outputs":[]}]}